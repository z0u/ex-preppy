{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191d5190",
   "metadata": {},
   "source": [
    "# Experiment 2.11: Measure label coverage required for effective weak supervision\n",
    "\n",
    "In earlier experiments, we have shown that weak supervision is sufficient to produce a well-structure latent space. Our regularizers are selectively applied to samples based on their labels, but the labels are noisy. For example, the color $(1,0,0)$ is labelled \"red\" only 50% of the time, and other colors may be labelled \"red\" too — only less often. But the choice of 50% was arbitrary, and we never really explored what proportion of samples actually needed to be labelled.\n",
    "\n",
    "In this experiment, we'll train the color autoencoder several times with different label coverage, and see what proportion of the training data needs to be labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db26371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "nbid = '2.11'  # ID for tagging assets\n",
    "nbname = 'Measure label coverage required for effective weak supervision'\n",
    "experiment_name = f'Ex {nbid}: {nbname}'\n",
    "project = 'ex-preppy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf0edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup: Logging, Experiment (Modal)\n",
    "import logging\n",
    "\n",
    "import modal\n",
    "\n",
    "from infra.requirements import freeze, project_packages\n",
    "from mini.experiment import Experiment\n",
    "from utils.logging import SimpleLoggingConfig\n",
    "\n",
    "logging_config = (\n",
    "    SimpleLoggingConfig()\n",
    "    .info('notebook', 'utils', 'mini', 'ex_color')\n",
    "    .error('matplotlib.axes')  # Silence warnings about set_aspect\n",
    ")\n",
    "logging_config.apply()\n",
    "\n",
    "# This is the logger for this notebook\n",
    "log = logging.getLogger(f'notebook.{nbid}')\n",
    "\n",
    "run = Experiment(experiment_name, project=project)\n",
    "run.image = modal.Image.debian_slim().pip_install(*freeze(all=True)).add_local_python_source(*project_packages())\n",
    "run.before_each(logging_config.apply)\n",
    "None  # prevent auto-display of this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2028d",
   "metadata": {},
   "source": [
    "## Regularizers\n",
    "\n",
    "- **Anchor:** pins `red` to $(1,0,0,0)$\n",
    "- **Anti-anchor:** repels everything from $(-1,0,0,0)$\n",
    "- **Separate:** angular repulsion to reduce global clumping (applied within each batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac781a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from mini.temporal.dopesheet import Dopesheet\n",
    "from ex_color.loss import AngularAnchor, Separate, RegularizerConfig, Planarity\n",
    "\n",
    "from ex_color.training import TrainingModule\n",
    "\n",
    "K = 4  # bottleneck dimensionality\n",
    "RED = (1, 0, 0, 0)\n",
    "ANTI_RED = tuple(-c for c in RED)\n",
    "assert len(RED) == len(ANTI_RED) == K\n",
    "\n",
    "ALL_REGULARIZERS = [\n",
    "    # RegularizerConfig(\n",
    "    #     name='reg-unit',\n",
    "    #     compute_loss_term=Unitarity(),\n",
    "    #     label_affinities=None,\n",
    "    #     layer_affinities=['encoder'],\n",
    "    # ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-anchor',\n",
    "        compute_loss_term=AngularAnchor(torch.tensor(RED, dtype=torch.float32)),\n",
    "        label_affinities={'red': 1.0},\n",
    "        layer_affinities=['bottleneck'],\n",
    "        phase=('train', 'validate'),\n",
    "    ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-separate',\n",
    "        compute_loss_term=Separate(power=100.0, shift=True),\n",
    "        label_affinities=None,\n",
    "        layer_affinities=['bottleneck'],\n",
    "    ),\n",
    "    # RegularizerConfig(\n",
    "    #     name='reg-anti-anchor',\n",
    "    #     compute_loss_term=AntiAnchor(torch.tensor(ANTI_RED, dtype=torch.float32)),\n",
    "    #     label_affinities=None,\n",
    "    #     layer_affinities=['bottleneck'],\n",
    "    # ),\n",
    "    RegularizerConfig(\n",
    "        name='reg-planar',\n",
    "        compute_loss_term=Planarity(),\n",
    "        label_affinities={'vibrant': 1.0},\n",
    "        layer_affinities=['bottleneck'],\n",
    "        phase=('train', 'validate'),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22376072",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is still a color cube, but this time we'll use an RGB cube for training instead of the HSV cube: since HSV has an over-representation of black and white, it would skew the label counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de07fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "import numpy as np\n",
    "\n",
    "from ex_color.data.color_cube import ColorCube\n",
    "from ex_color.data.cube_dataset import CubeDataset, redness, vibrancy, stochastic_labels, exact_labels\n",
    "\n",
    "# from ex_color.data.cube_sampler import vibrancy\n",
    "from ex_color.data.cyclic import arange_cyclic\n",
    "\n",
    "\n",
    "def prep_data() -> DataLoader:\n",
    "    cube = ColorCube.from_rgb(\n",
    "        r=np.linspace(0, 1, 10),\n",
    "        g=np.linspace(0, 1, 10),\n",
    "        b=np.linspace(0, 1, 10),\n",
    "    )\n",
    "    cube = cube.assign(\n",
    "        red=redness(cube['color']) ** 10 * 0.07,\n",
    "        vibrant=vibrancy(cube['color']) ** 100 * 0.02,\n",
    "    )\n",
    "    dataset = CubeDataset(cube)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "        sampler=RandomSampler(dataset, num_samples=len(dataset), replacement=True),\n",
    "        collate_fn=stochastic_labels,\n",
    "    )\n",
    "\n",
    "\n",
    "def prep_val_data() -> DataLoader:\n",
    "    cube = ColorCube.from_rgb(\n",
    "        r=np.linspace(0, 1, 4),\n",
    "        g=np.linspace(0, 1, 4),\n",
    "        b=np.linspace(0, 1, 4),\n",
    "    )\n",
    "    cube = cube.assign(\n",
    "        red=redness(cube['color']) == 1,\n",
    "        vibrant=vibrancy(cube['color']) == 1,\n",
    "    )\n",
    "    dataset = CubeDataset(cube)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        # batch_size=len(dataset),\n",
    "        num_workers=4,\n",
    "        collate_fn=exact_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecb906",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Like in Ex 2.2, the model is trained with PyTorch Lightning, with regularizers applied as custom hooks.\n",
    "\n",
    "Unlike earlier experiments, the model now has two nonlinear activation functions in the encoder and decoder, to allow the latent space to be warped more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73c22398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from ex_color.callbacks import LabelProportionCallback\n",
    "from ex_color.model import CNColorMLP\n",
    "\n",
    "\n",
    "# @run.thither(env={'WANDB_API_KEY': wandb.Api().api_key})\n",
    "async def train(\n",
    "    dopesheet: Dopesheet,\n",
    "    regularizers: list[RegularizerConfig],\n",
    "    k_bottleneck: int,\n",
    ") -> CNColorMLP:\n",
    "    \"\"\"Train the model with the given dopesheet and variant.\"\"\"\n",
    "    import lightning as L\n",
    "    from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "    from ex_color.seed import set_deterministic_mode\n",
    "\n",
    "    from utils.progress.lightning import LightningProgress\n",
    "\n",
    "    log.info(f'Training with: {[r.name for r in regularizers]}')\n",
    "\n",
    "    seed = 0\n",
    "    set_deterministic_mode(seed)\n",
    "\n",
    "    train_loader = prep_data()\n",
    "    val_loader = prep_val_data()\n",
    "\n",
    "    model = CNColorMLP(k_bottleneck, n_nonlinear=1)\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    log.debug(f'Model initialized with {total_params:,} trainable parameters.')\n",
    "\n",
    "    training_module = TrainingModule(model, dopesheet, torch.nn.MSELoss(), regularizers)\n",
    "\n",
    "    logger = WandbLogger(experiment_name, project=project)\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_steps=len(dopesheet),\n",
    "        callbacks=[\n",
    "            LightningProgress(),\n",
    "            LabelProportionCallback(prefix='labels', get_active_labels=lambda: training_module.active_labels),\n",
    "        ],\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        # enable_progress_bar=True,\n",
    "        check_val_every_n_epoch=10,\n",
    "        logger=logger,\n",
    "        log_every_n_steps=min(50, len(train_loader)),\n",
    "    )\n",
    "\n",
    "    print(f'max_steps: {len(dopesheet)}, train_loader length: {len(train_loader)}')\n",
    "\n",
    "    # Train the model\n",
    "    try:\n",
    "        trainer.fit(training_module, train_loader, val_loader)\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "    # This is only a small model, so it's OK to return it rather than storing and loading a checkpoint remotely\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9688ac3",
   "metadata": {},
   "source": [
    "## Inference utils\n",
    "\n",
    "We wrap the model that we trained above in an `InferenceModule`. We won't be using its intervention features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d2de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ex_color.inference import InferenceModule\n",
    "\n",
    "\n",
    "async def infer(\n",
    "    model: CNColorMLP,\n",
    "    test_data: Tensor,\n",
    ") -> Tensor:\n",
    "    \"\"\"Run inference with the given model.\"\"\"\n",
    "    import lightning as L\n",
    "\n",
    "    inference_module = InferenceModule(model, [])\n",
    "    trainer = L.Trainer(\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "    reconstructed_colors_batches = trainer.predict(\n",
    "        inference_module,\n",
    "        DataLoader(\n",
    "            TensorDataset(test_data.reshape((-1, 3))),\n",
    "            batch_size=64,\n",
    "            collate_fn=lambda batch: torch.stack([row[0] for row in batch], 0),\n",
    "        ),\n",
    "    )\n",
    "    assert reconstructed_colors_batches is not None\n",
    "    # Flatten the list of batches to a single list of tensors\n",
    "    reconstructed_colors = [item for batch in reconstructed_colors_batches for item in batch]\n",
    "    # Reshape to match input\n",
    "    return torch.cat(reconstructed_colors).reshape(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ec7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ex_color.inference import InferenceModule\n",
    "\n",
    "\n",
    "async def infer_with_latent_capture(\n",
    "    model: CNColorMLP,\n",
    "    test_data: Tensor,\n",
    "    layer_name: str = 'bottleneck',\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    module = InferenceModule(model, [], capture_layers=[layer_name])\n",
    "    import lightning as L\n",
    "\n",
    "    trainer = L.Trainer(enable_checkpointing=False, enable_model_summary=False, enable_progress_bar=False)\n",
    "    batches = trainer.predict(\n",
    "        module,\n",
    "        DataLoader(\n",
    "            TensorDataset(test_data.reshape((-1, 3))),\n",
    "            batch_size=64,\n",
    "            collate_fn=lambda batch: torch.stack([row[0] for row in batch], 0),\n",
    "        ),\n",
    "    )\n",
    "    assert batches is not None\n",
    "    preds = [item for batch in batches for item in batch]\n",
    "    y = torch.cat(preds).reshape(test_data.shape)\n",
    "    # Read captured activations as a flat [N, D] tensor\n",
    "    latents = module.read_captured(layer_name)\n",
    "    return y, latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4381b363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.11-true-colors.dark.png?v=3XRDyVyJ0EzpsvUSBcO7Y3mi-oK3pvyxlMtnZHNIGqg\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.11-true-colors.png?v=3XRDyVyJ0EzpsvUSBcO7Y3mi-oK3pvyxlMtnZHNIGqg\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.11-true-colors.png?v=3XRDyVyJ0EzpsvUSBcO7Y3mi-oK3pvyxlMtnZHNIGqg\" alt=\"Plot showing four slices of the HSV cube, titled &quot;True colors · V vs H by S&quot;. Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"True colors · V vs H by S\". Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_colors\n",
    "from utils.nb import displayer_mpl\n",
    "\n",
    "\n",
    "hsv_cube = ColorCube.from_hsv(\n",
    "    h=arange_cyclic(step_size=1 / 24),\n",
    "    s=np.linspace(0, 1, 4),\n",
    "    v=np.linspace(0, 1, 8),\n",
    ").permute('svh')\n",
    "x_hsv = torch.tensor(hsv_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "hd_hsv_cube = ColorCube.from_hsv(\n",
    "    h=arange_cyclic(step_size=1 / 240),\n",
    "    s=np.linspace(0, 1, 48),\n",
    "    v=np.linspace(0, 1, 48),\n",
    ")\n",
    "hd_x_hsv = torch.tensor(hd_hsv_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "rgb_cube = ColorCube.from_rgb(\n",
    "    r=np.linspace(0, 1, 20),\n",
    "    g=np.linspace(0, 1, 20),\n",
    "    b=np.linspace(0, 1, 20),\n",
    ")\n",
    "x_rgb = torch.tensor(rgb_cube.rgb_grid, dtype=torch.float32)\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-true-colors.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{title}\". Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum.\"\"\",\n",
    ") as show:\n",
    "    show(lambda: plot_colors(hsv_cube, title='True colors', colors=x_hsv.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e2649",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68d49db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 100.9 no.2.11:Training with: ['reg-anchor', 'reg-separate', 'reg-planar']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 100.9 li.fa.ut.se:Seed set to 0\n",
      "I 100.9 ex.se: PyTorch set to deterministic mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 101.1 li.py.ut.ra:GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 101.1 li.py.ut.ra:TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 101.1 li.py.ut.ra:HPU available: False, using: 0 HPUs\n",
      "max_steps: 1501, train_loader length: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250917_014239-2amv5t5u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/z0r/ex-preppy/runs/2amv5t5u' target=\"_blank\">Ex 2.11: Measure label coverage required for effective weak supervision</a></strong> to <a href='https://wandb.ai/z0r/ex-preppy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/z0r/ex-preppy' target=\"_blank\">https://wandb.ai/z0r/ex-preppy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/z0r/ex-preppy/runs/2amv5t5u' target=\"_blank\">https://wandb.ai/z0r/ex-preppy/runs/2amv5t5u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width: 100%; padding: 5px 0; font-family: monospace\">\n",
       "  <div style=\"position: relative; height: calc(1em * 5/3); width: 100%; margin-bottom: 2em\">\n",
       "    <div style=\"position: absolute; top: 100%; height: 3.5px; left: 0; width: 100%; background: linear-gradient(to right, var(--h1) 0.0%, var(--h1) 2.0%, var(--h1) 4.1%, var(--h1) 6.1%, var(--h1) 8.2%, var(--h1) 10.2%, var(--h1) 12.2%, var(--h1) 14.3%, var(--h0) 16.3%, var(--h1) 18.4%, var(--h1) 20.4%, var(--h1) 22.4%, var(--h1) 24.5%, var(--h1) 26.5%, var(--h1) 28.6%, var(--h1) 30.6%, var(--h0) 32.7%, var(--h1) 34.7%, var(--h1) 36.7%, var(--h1) 38.8%, var(--h1) 40.8%, var(--h1) 42.9%, var(--h1) 44.9%, var(--h1) 46.9%, var(--h0) 49.0%, var(--h1) 51.0%, var(--h1) 53.1%, var(--h1) 55.1%, var(--h1) 57.1%, var(--h1) 59.2%, var(--h1) 61.2%, var(--h1) 63.3%, var(--h0) 65.3%, var(--h1) 67.3%, var(--h1) 69.4%, var(--h1) 71.4%, var(--h1) 73.5%, var(--h1) 75.5%, var(--h1) 77.6%, var(--h1) 79.6%, var(--h0) 81.6%, var(--h1) 83.7%, var(--h1) 85.7%, var(--h1) 87.8%, var(--h1) 89.8%, var(--h1) 91.8%, var(--h1) 93.9%, var(--h1) 95.9%, var(--h0) 98.0%, var(--h2) 100.0%);--h0:color(from currentColor srgb r g b / 0.06);--h1:color(from currentColor srgb r g b / 0.25);--h2:color(from currentColor srgb r g b / 0.56)\"></div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: -0.1%; border-left: 0.5px solid currentColor\">0.0278</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 9.5%; border-left: 0.5px solid currentColor\">0.0278</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 19.1%; border-left: 0.5px solid currentColor\">0.0055</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 28.7%; border-left: 0.5px solid currentColor\">0.0069</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 38.3%; border-left: 0.5px solid currentColor\">0.0144</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 47.9%; border-left: 0.5px solid currentColor\">0.0021</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 57.5%; border-left: 0.5px solid currentColor\">0.0028</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 67.1%; border-left: 0.5px solid currentColor\">0.0016</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 76.7%; border-left: 0.5px solid currentColor\">0.0008</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 86.3%; border-left: 0.5px solid currentColor\">0.0003</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; right: 0.1%; border-right: 0.5px solid currentColor\">0.0002</div>\n",
       "    <div style=\"position: absolute; bottom: -4px; left: calc(100.0% - 4px)\">\n",
       "      <div style=\"border-left: 4px solid transparent; border-right: 4px solid transparent; border-bottom: 4px solid currentColor\"></div>\n",
       "    </div>\n",
       "    <div style=\"position: absolute; height: 100%; width: 100.0%; background-color: color(from currentColor srgb r g b / 0.1); border-bottom: 1px solid currentColor\"></div>\n",
       "    <div style=\"position: absolute; width: 100%; height: 100%; text-align: center; line-height: calc((1em * 5/3) / 0.9); font-size: 90%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; border-bottom: 1px dashed color(from currentColor srgb r g b / 0.5)\"><b>Training</b>: 100.0% [1501/1501] [<b>00:15</b>/<00:00, 98.67 it/s]</div>\n",
       "  </div>\n",
       "  <div style=\"display: grid; grid-template-columns: repeat(3, minmax(80px, 1fr)); gap: 5px 0px; width: 100%; margin: 1em 0; font-size: 0.85em\">\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">v_num</div>\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">val_loss</div>\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">train_loss</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">5t5u</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">0.0002061</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">9.256e-05</div>\n",
       "  </div>\n",
       "</div>"
      ],
      "text/plain": [
       "Training: 100.0% [1501/1501]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting phase: Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=1501` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 117.6 li.py.ut.ra:`Trainer.fit` stopped: `max_steps=1501` reached.\n",
      "I 117.6 ex.ca.la:Label frequencies (n=89064): _any: 0.162%, red: 0.049%, vibrant: 0.113%\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>labels/_any</td><td>▁</td></tr><tr><td>labels/epoch/_any</td><td>█▃▃▃▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>labels/epoch/red</td><td>█▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>labels/epoch/vibrant</td><td>▅▁▅▅█▄▄▃▄▃▃▃▃▄▅▅▅▅▅▅▅▅▆▆▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>labels/red</td><td>▁</td></tr><tr><td>labels/vibrant</td><td>▁</td></tr><tr><td>train_loss</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_recon</td><td>█▁▁▁▁▁▁▁▁▁▁▁▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_reg-anchor</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_reg-planar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_reg-separate</td><td>█▂▂▁▂▁▁▂▁▁▃▁▁▂▂▂▂▁▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇████</td></tr><tr><td>val_loss</td><td>▄▄█▂▂▂▁▁▁</td></tr><tr><td>val_recon</td><td>▄▄█▂▂▂▁▁▁</td></tr><tr><td>val_reg-anchor</td><td>█▃▁▁▁▁▁▁▁</td></tr><tr><td>val_reg-planar</td><td>▇█▂▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>92</td></tr><tr><td>labels/_any</td><td>0.00162</td></tr><tr><td>labels/epoch/_any</td><td>0.00162</td></tr><tr><td>labels/epoch/red</td><td>0.00049</td></tr><tr><td>labels/epoch/vibrant</td><td>0.00113</td></tr><tr><td>labels/red</td><td>0.00049</td></tr><tr><td>labels/vibrant</td><td>0.00113</td></tr><tr><td>train_loss</td><td>6e-05</td></tr><tr><td>train_recon</td><td>6e-05</td></tr><tr><td>train_reg-anchor</td><td>0</td></tr><tr><td>train_reg-planar</td><td>0.04656</td></tr><tr><td>train_reg-separate</td><td>0.25747</td></tr><tr><td>trainer/global_step</td><td>1487</td></tr><tr><td>val_loss</td><td>0.00021</td></tr><tr><td>val_recon</td><td>0.00021</td></tr><tr><td>val_reg-anchor</td><td>0.00069</td></tr><tr><td>val_reg-planar</td><td>0.01331</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Ex 2.11: Measure label coverage required for effective weak supervision</strong> at: <a href='https://wandb.ai/z0r/ex-preppy/runs/2amv5t5u' target=\"_blank\">https://wandb.ai/z0r/ex-preppy/runs/2amv5t5u</a><br> View project at: <a href='https://wandb.ai/z0r/ex-preppy' target=\"_blank\">https://wandb.ai/z0r/ex-preppy</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250917_014239-2amv5t5u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with run():\n",
    "    model_no_unit = await train(Dopesheet.from_csv(f'./ex-{nbid}-dopesheet.csv'), ALL_REGULARIZERS, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af153b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.11-pred-colors-no-intervention.dark.png?v=yagAjG70V6Tvb3ado_p5bc_GvaLDgAMTRy6SmLq2r5c\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.11-pred-colors-no-intervention.png?v=yagAjG70V6Tvb3ado_p5bc_GvaLDgAMTRy6SmLq2r5c\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.11-pred-colors-no-intervention.png?v=yagAjG70V6Tvb3ado_p5bc_GvaLDgAMTRy6SmLq2r5c\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors · no intervention · V vs H by S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors · no intervention · V vs H by S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.11-loss-colors-no-intervention.dark.png?v=VL0LZ_5rxqIqCRu7qNu1elNkb7adoMa3WiLt_FKCnJA\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.11-loss-colors-no-intervention.png?v=VL0LZ_5rxqIqCRu7qNu1elNkb7adoMa3WiLt_FKCnJA\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.11-loss-colors-no-intervention.png?v=VL0LZ_5rxqIqCRu7qNu1elNkb7adoMa3WiLt_FKCnJA\" alt=\"Line chart showing loss per color, titled &quot;Reconstruction error · no intervention&quot;. Y-axis: mean square error, ranging from zero to 0.0015. X-axis: hue.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Line chart showing loss per color, titled \"Reconstruction error · no intervention\". Y-axis: mean square error, ranging from zero to 0.0015. X-axis: hue."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss: 0.0015\n",
      "Median MSE: 4.3e-05\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from ex_color.vis import plot_colors, plot_cube_series\n",
    "\n",
    "\n",
    "interventions = []\n",
    "y_hsv = await infer(model_no_unit, x_hsv)\n",
    "hd_y_hsv = await infer(model_no_unit, hd_x_hsv)\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-pred-colors-no-intervention.png',\n",
    "    alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{title}\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_colors(\n",
    "            hsv_cube,\n",
    "            title='Predicted colors · no intervention',\n",
    "            colors=y_hsv.numpy(),\n",
    "            colors_compare=x_hsv.numpy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "per_color_loss = F.mse_loss(hd_y_hsv, hd_x_hsv, reduction='none').mean(dim=-1)\n",
    "loss_cube = hd_hsv_cube.assign('MSE', per_color_loss.numpy().reshape(hd_hsv_cube.shape))\n",
    "max_loss = per_color_loss.max().item()\n",
    "median_loss = per_color_loss.median().item()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-loss-colors-no-intervention.png',\n",
    "    alt_text=f\"\"\"Line chart showing loss per color, titled \"{{title}}\". Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda: plot_cube_series(\n",
    "            loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "            loss_cube.permute('svh')[:, -1:, :: -(loss_cube.shape[0] // -3)],\n",
    "            loss_cube.permute('vsh')[:, -1:, :: -(loss_cube.shape[0] // -3)],\n",
    "            title='Reconstruction error · no intervention',\n",
    "            var='MSE',\n",
    "            figsize=(12, 3),\n",
    "        )\n",
    "    )\n",
    "print(f'Max loss: {max_loss:.2g}')\n",
    "print(f'Median MSE: {median_loss:.2g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f65671ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.11-latents-no-intervention.dark.png?v=DyJQUJLpEXM8YUy2hcH8-Sn1D2I34Oz8wfaFnk-FSK8\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.11-latents-no-intervention.png?v=DyJQUJLpEXM8YUy2hcH8-Sn1D2I34Oz8wfaFnk-FSK8\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.11-latents-no-intervention.png?v=DyJQUJLpEXM8YUy2hcH8-Sn1D2I34Oz8wfaFnk-FSK8\" alt=\"Three spherical plots, titled &quot;Latents · no intervention&quot;. Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a sphere.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Three spherical plots, titled \"Latents · no intervention\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a sphere."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.vis import plot_latent_grid_3d\n",
    "\n",
    "y_rgb, h_rgb = await infer_with_latent_capture(model_no_unit, x_rgb, 'bottleneck')\n",
    "clear_output()\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-latents-no-intervention.png',\n",
    "    alt_text=\"\"\"Three spherical plots, titled \"{title}\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a sphere.\"\"\",\n",
    ") as show:\n",
    "    show(\n",
    "        lambda theme: plot_latent_grid_3d(\n",
    "            h_rgb,\n",
    "            y_rgb,\n",
    "            x_rgb,\n",
    "            title='Latents · no intervention',\n",
    "            dims=[(1, 0, 2), (1, 2, 0), (3, 2, 0)],\n",
    "            dot_radius=10,\n",
    "            theme=theme,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17177769",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-color-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
