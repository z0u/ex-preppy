{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191d5190",
   "metadata": {},
   "source": [
    "# Experiment 2.10: Delete only red without \"desaturated\" label\n",
    "\n",
    "In [Ex 2.9](ex-2.9-delete-only-red-5d.ipynb) we succeed in deleting _red_ without deleting _cyan_ or other colors, with precision similar to an intervention with a cosine falloff. In that experiment, we used a subspace regularizer to attract _desaturated_ colors to the last three dimensions. Let's see if we can get similar results without that label. We'll also try removing the unitarity regularizer to verify that it's still needed.\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "If we weakly repel _all_ embeddings from the anchor dimension, then we will be able to delete _red_ without also deleting other colors. We should see error vs. color curves similar to those achieved in 2.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db26371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "nbid = '2.10.1'  # ID for tagging assets\n",
    "nbname = 'Ablate red (only), 5D, fewer labels'\n",
    "experiment_name = f'Ex {nbid}: {nbname}'\n",
    "project = 'ex-preppy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf0edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup: Logging, Experiment (Modal)\n",
    "import logging\n",
    "\n",
    "import modal\n",
    "\n",
    "from infra.requirements import freeze, project_packages\n",
    "from mini.experiment import Experiment\n",
    "from utils.logging import SimpleLoggingConfig\n",
    "\n",
    "logging_config = (\n",
    "    SimpleLoggingConfig()\n",
    "    .info('notebook', 'utils', 'mini', 'ex_color')\n",
    "    .error('matplotlib.axes')  # Silence warnings about set_aspect\n",
    ")\n",
    "logging_config.apply()\n",
    "\n",
    "# This is the logger for this notebook\n",
    "log = logging.getLogger(f'notebook.{nbid}')\n",
    "\n",
    "run = Experiment(experiment_name, project=project)\n",
    "run.image = modal.Image.debian_slim().pip_install(*freeze(all=True)).add_local_python_source(*project_packages())\n",
    "run.before_each(logging_config.apply)\n",
    "None  # prevent auto-display of this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2028d",
   "metadata": {},
   "source": [
    "## Model parameters\n",
    "\n",
    "Like Ex 2.9, we use the following regularizers:\n",
    "\n",
    "- **Anchor:** pins `red` to $(1,0,0,0,0)$ (5D)\n",
    "- **AxisAlignedSubspace:** repels everything from dimension $1$ (with varying weight, see schedule)\n",
    "- **Separate:** angular repulsion to reduce global clumping (applied within each batch)\n",
    "\n",
    "Since we're isolating _red_, we have 5D latent embeddings and two nonlinear activation functions in the encoder and decoder, to allow the latent space to be warped more.\n",
    "\n",
    "But unlike 2.9:\n",
    "- **Anti-anchor:** has been removed, relying on anti-subspace to keep other concepts clear of the dimension to be ablated.\n",
    "- **Unitarity:** is present in this list, but we'll do a run without it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac781a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from ex_color.loss import AngularAnchor, AxisAlignedSubspace, Separate, RegularizerConfig\n",
    "\n",
    "from ex_color.training import TrainingModule\n",
    "\n",
    "K = 5  # bottleneck dimensionality\n",
    "N = 2  # number of nonlinear layers\n",
    "RED = (1, 0, 0, 0, 0)\n",
    "\n",
    "reg_separate = RegularizerConfig(\n",
    "    name='reg-separate',\n",
    "    compute_loss_term=Separate(power=100.0, shift=True),\n",
    "    label_affinities=None,\n",
    "    layer_affinities=['bottleneck'],\n",
    ")\n",
    "reg_anchor = RegularizerConfig(\n",
    "    name='reg-anchor',\n",
    "    compute_loss_term=AngularAnchor(torch.tensor(RED, dtype=torch.float32)),\n",
    "    label_affinities={'red': 1.0},\n",
    "    layer_affinities=['bottleneck'],\n",
    "    phase=('train', 'validate'),\n",
    ")\n",
    "reg_anti_subspace = RegularizerConfig(\n",
    "    name='reg-anti-subspace',\n",
    "    compute_loss_term=AxisAlignedSubspace((0,), invert=True),\n",
    "    label_affinities=None,\n",
    "    layer_affinities=['bottleneck'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f09f0f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Parameter schedule \n",
       "|   STEP | PHASE   |   ACTION |      lr |   reg-separate |   reg-anchor |   reg-anti-subspace |\n",
       "|-------:|:--------|---------:|--------:|---------------:|-------------:|--------------------:|\n",
       "|      0 | Train   |          |   1e-08 |                |         0    |                0.25 |\n",
       "|     10 |         |          |   0.01  |                |              |                     |\n",
       "|    375 |         |          |         |                |              |                0.1  |\n",
       "|    750 |         |          |   0.1   |           0.01 |         0.15 |                0.03 |\n",
       "|   1425 |         |          |   0.1   |           0    |         0    |                0    |\n",
       "|   1500 |         |          |   0.05  |                |              |                     |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.10.1-dopesheet.dark.png?v=RSheAy2n_6gw6rIfzLgbhnULi_cvcwOC-UARi69hNCI\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.10.1-dopesheet.png?v=RSheAy2n_6gw6rIfzLgbhnULi_cvcwOC-UARi69hNCI\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.10.1-dopesheet.png?v=RSheAy2n_6gw6rIfzLgbhnULi_cvcwOC-UARi69hNCI\" alt=\"Plot showing the parameter schedule for the training run, titled &quot;&quot;. The plot has two sections: the upper section shows various regularization weights over time, and the lower section shows the learning rate over time. The x-axis represents training steps.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing the parameter schedule for the training run, titled \"\". The plot has two sections: the upper section shows various regularization weights over time, and the lower section shows the learning rate over time. The x-axis represents training steps."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from mini.temporal.dopesheet import Dopesheet\n",
    "from mini.temporal.timeline import Timeline\n",
    "from mini.temporal.vis import plot_timeline, realize_timeline, ParamGroup\n",
    "from utils.nb import displayer_mpl\n",
    "from utils.plt import Theme\n",
    "\n",
    "dopesheet = Dopesheet.from_csv(f'./ex-{nbid}-dopesheet.csv')\n",
    "\n",
    "display(Markdown(f\"\"\"## Parameter schedule \\n{dopesheet.to_markdown()}\"\"\"))\n",
    "\n",
    "\n",
    "def plot_dopesheet(dopesheet: Dopesheet, theme: Theme):\n",
    "    timeline = Timeline(dopesheet)\n",
    "    history_df = realize_timeline(timeline)\n",
    "    keyframes_df = dopesheet.as_df()\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 3), constrained_layout=True)\n",
    "    axs = fig.subplots(2, 1, sharex=True, height_ratios=[3, 1])\n",
    "    ax1, ax2 = cast(tuple[Axes, ...], axs)\n",
    "\n",
    "    plot_timeline(\n",
    "        history_df,\n",
    "        keyframes_df,\n",
    "        groups=(ParamGroup(name='', params=[p for p in dopesheet.props if p not in {'lr'}]),),\n",
    "        theme=theme,\n",
    "        ax=ax1,\n",
    "        show_phase_labels=False,\n",
    "    )\n",
    "    ax1.set_ylabel('Weight')\n",
    "    ax1.set_xlabel('')\n",
    "\n",
    "    plot_timeline(\n",
    "        history_df,\n",
    "        keyframes_df,\n",
    "        groups=(ParamGroup(name='', params=['lr']),),\n",
    "        theme=theme,\n",
    "        ax=ax2,\n",
    "        show_legend=False,\n",
    "        show_phase_labels=False,\n",
    "    )\n",
    "    ax2.set_ylabel('LR')\n",
    "\n",
    "    # add a little space on the y-axis extents\n",
    "    ax1.set_ylim(ax1.get_ylim()[0] * 1.1, ax1.get_ylim()[1] * 1.1)\n",
    "    ax2.set_ylim(ax2.get_ylim()[0] * 1.1, ax2.get_ylim()[1] * 1.1)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "with displayer_mpl(\n",
    "    f'large-assets/ex-{nbid}-dopesheet.png',\n",
    "    alt_text=\"\"\"Plot showing the parameter schedule for the training run, titled \"{title}\". The plot has two sections: the upper section shows various regularization weights over time, and the lower section shows the learning rate over time. The x-axis represents training steps.\"\"\",\n",
    ") as show:\n",
    "    show(lambda theme: plot_dopesheet(dopesheet, theme))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22376072",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Data is the same as last time: color cubes with values in RGB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89508e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "import numpy as np\n",
    "\n",
    "from ex_color.data.color_cube import ColorCube\n",
    "from ex_color.data.cube_dataset import CubeDataset, redness, stochastic_labels, exact_labels\n",
    "\n",
    "# from ex_color.data.cube_sampler import vibrancy\n",
    "from ex_color.data.cyclic import arange_cyclic\n",
    "\n",
    "\n",
    "def prep_data() -> DataLoader:\n",
    "    cube = ColorCube.from_rgb(\n",
    "        r=np.linspace(0, 1, 10),\n",
    "        g=np.linspace(0, 1, 10),\n",
    "        b=np.linspace(0, 1, 10),\n",
    "    )\n",
    "    # Softly label _red_ - will be stochastically discretized in the dataloader\n",
    "    cube = cube.assign(\n",
    "        red=redness(cube['color']) ** 8 * 0.08,\n",
    "        # vibrant=vibrancy(cube['color']) ** 100 * 0.02,\n",
    "        # desaturated=(1 - vibrancy(cube['color'])) ** 10 * 0.02,\n",
    "    )\n",
    "    dataset = CubeDataset(cube)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=64,\n",
    "        num_workers=4,\n",
    "        sampler=RandomSampler(dataset, num_samples=len(dataset), replacement=True),\n",
    "        collate_fn=stochastic_labels,\n",
    "    )\n",
    "\n",
    "\n",
    "def prep_val_data() -> DataLoader:\n",
    "    cube = ColorCube.from_rgb(\n",
    "        r=np.linspace(0, 1, 4),\n",
    "        g=np.linspace(0, 1, 4),\n",
    "        b=np.linspace(0, 1, 4),\n",
    "    )\n",
    "    # Exact labels for validation: we only check where the prototypes are located\n",
    "    cube = cube.assign(\n",
    "        red=redness(cube['color']) == 1,\n",
    "        # vibrant=vibrancy(cube['color']) == 1,\n",
    "    )\n",
    "    dataset = CubeDataset(cube)\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        # batch_size=len(dataset),\n",
    "        num_workers=2,\n",
    "        collate_fn=exact_labels,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4381b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from ex_color.data.color_cube import ColorCube\n",
    "from ex_color.data.cyclic import arange_cyclic\n",
    "\n",
    "\n",
    "hsv_cube = ColorCube.from_hsv(\n",
    "    h=arange_cyclic(step_size=1 / 12),\n",
    "    s=np.linspace(0, 1, 4),\n",
    "    v=np.linspace(0, 1, 5),\n",
    ")\n",
    "\n",
    "n_h = hsv_cube.shape[0]\n",
    "\n",
    "hd_hsv_cube = ColorCube.from_hsv(\n",
    "    # Extend hue range to encompass the end pixels of the low-res cube above\n",
    "    h=np.linspace(0 - 1 / n_h, 1 + 1 / n_h, 300),\n",
    "    s=np.linspace(0, 1, 48),\n",
    "    v=np.linspace(0, 1, 48),\n",
    ")\n",
    "hd_hsv_cube = hd_hsv_cube[::2, ::2, ::2]\n",
    "\n",
    "rgb_cube = ColorCube.from_rgb(\n",
    "    r=np.linspace(0, 1, 20),\n",
    "    g=np.linspace(0, 1, 20),\n",
    "    b=np.linspace(0, 1, 20),\n",
    ")\n",
    "\n",
    "# with displayer_mpl(\n",
    "#     f'large-assets/ex-{nbid}-true-colors.png',\n",
    "#     alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{title}\". Each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. The first slice shows a grayscale gradient from black to white; the last shows the fully-saturated color spectrum.\"\"\",\n",
    "# ) as show:\n",
    "#     show(lambda: plot_colors(hsv_cube, title='True colors'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecb906",
   "metadata": {},
   "source": [
    "## Training & inference utils\n",
    "\n",
    "Like in Ex 2.2..2.9, the model is trained with PyTorch Lightning, with regularizers applied as custom hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c22398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import gettempdir\n",
    "import wandb\n",
    "from ex_color.model import CNColorMLP\n",
    "\n",
    "\n",
    "# @run.thither(env={'WANDB_API_KEY': wandb.Api().api_key})\n",
    "async def train(\n",
    "    dopesheet: Dopesheet,\n",
    "    regularizers: list[RegularizerConfig],\n",
    "    k_bottleneck: int,\n",
    "    n_nonlinear: int,\n",
    "    *,\n",
    "    seed: int | None = None,\n",
    ") -> CNColorMLP:\n",
    "    \"\"\"Train the model with the given dopesheet and variant.\"\"\"\n",
    "    import lightning as L\n",
    "    from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "    from ex_color.callbacks import LabelProportionCallback\n",
    "    from ex_color.seed import set_deterministic_mode\n",
    "\n",
    "    from utils.progress.lightning import LightningProgress\n",
    "\n",
    "    log.info(f'Training with: {[r.name for r in regularizers]}')\n",
    "\n",
    "    if seed is not None:\n",
    "        set_deterministic_mode(seed)\n",
    "\n",
    "    train_loader = prep_data()\n",
    "    val_loader = prep_val_data()\n",
    "\n",
    "    model = CNColorMLP(k_bottleneck, n_nonlinear=n_nonlinear)\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    log.debug(f'Model initialized with {total_params:,} trainable parameters.')\n",
    "\n",
    "    training_module = TrainingModule(model, dopesheet, torch.nn.MSELoss(), regularizers)\n",
    "\n",
    "    logger = WandbLogger(experiment_name, project=project, save_dir=gettempdir())\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_steps=len(dopesheet),\n",
    "        callbacks=[\n",
    "            LightningProgress(),\n",
    "            LabelProportionCallback(prefix='labels', get_active_labels=lambda: training_module.active_labels),\n",
    "        ],\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        # enable_progress_bar=True,\n",
    "        check_val_every_n_epoch=10,\n",
    "        logger=logger,\n",
    "        log_every_n_steps=min(50, len(train_loader)),\n",
    "    )\n",
    "\n",
    "    print(f'max_steps: {len(dopesheet)}, train_loader length: {len(train_loader)}')\n",
    "\n",
    "    # Train the model\n",
    "    try:\n",
    "        trainer.fit(training_module, train_loader, val_loader)\n",
    "    finally:\n",
    "        wandb.finish()\n",
    "    # This is only a small model, so it's OK to return it rather than storing and loading a checkpoint remotely\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9688ac3",
   "metadata": {},
   "source": [
    "We wrap the model that we trained above in an `InferenceModule`. We won't be using its intervention features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89ec7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ex_color.inference import InferenceModule\n",
    "\n",
    "\n",
    "async def infer_with_latent_capture(\n",
    "    model: CNColorMLP,\n",
    "    test_data: Tensor,\n",
    "    layer_name: str = 'bottleneck',\n",
    ") -> tuple[Tensor, Tensor]:\n",
    "    module = InferenceModule(model, [], capture_layers=[layer_name])\n",
    "    import lightning as L\n",
    "\n",
    "    trainer = L.Trainer(enable_checkpointing=False, enable_model_summary=False, enable_progress_bar=False, logger=False)\n",
    "    batches = trainer.predict(\n",
    "        module,\n",
    "        DataLoader(\n",
    "            TensorDataset(test_data.reshape((-1, 3))),\n",
    "            batch_size=64,\n",
    "            collate_fn=lambda batch: torch.stack([row[0] for row in batch], 0),\n",
    "        ),\n",
    "    )\n",
    "    assert batches is not None\n",
    "    preds = [item for batch in batches for item in batch]\n",
    "    y = torch.cat(preds).reshape(test_data.shape)\n",
    "    # Read captured activations as a flat [N, D] tensor\n",
    "    latents = module.read_captured(layer_name)\n",
    "    return y, latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a359a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "async def test(model: CNColorMLP, test_data: ColorCube) -> ColorCube:\n",
    "    x = torch.tensor(test_data.rgb_grid, dtype=torch.float32)\n",
    "    y, h = await infer_with_latent_capture(model, x, 'bottleneck')\n",
    "    per_color_loss = F.mse_loss(y, x, reduction='none').mean(dim=-1)\n",
    "    return test_data.assign(\n",
    "        recon=y.numpy().reshape((*test_data.shape, -1)),\n",
    "        MSE=per_color_loss.numpy().reshape((*test_data.shape, -1)),\n",
    "        latents=h.numpy().reshape((*test_data.shape, -1)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41643004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate a list of dimensions to visualize\n",
    "# from itertools import combinations\n",
    "# [\n",
    "#     (\n",
    "#         b,\n",
    "#         a,\n",
    "#         (a + 1) % 5 if (a + 1) % 5 not in (a, b) else (a + 2) % 5,\n",
    "#     )\n",
    "#     for a, b in combinations((0, 1, 2, 3, 4), 2)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14da6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from ex_color.vis import (\n",
    "    plot_colors,\n",
    "    plot_cube_series,\n",
    "    plot_latent_grid_3d_from_cube,\n",
    ")\n",
    "from utils.nb import displayer_mpl\n",
    "\n",
    "\n",
    "def tags_for_file(tags: Sequence[str]) -> str:\n",
    "    import re\n",
    "\n",
    "    tags = [re.sub(r'[^a-zA-Z0-9]+', '-', tag.lower()) for tag in tags]\n",
    "    return '-'.join(tags)\n",
    "\n",
    "\n",
    "def visualize_reconstructed_cube(data: ColorCube, *, tags: Sequence[str] = ()):\n",
    "    with displayer_mpl(\n",
    "        f'large-assets/ex-{nbid}-pred-colors-{tags_for_file(tags)}.png',\n",
    "        alt_text=\"\"\"Plot showing four slices of the HSV cube, titled \"{title}\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color.\"\"\",\n",
    "    ) as show:\n",
    "        show(\n",
    "            lambda: plot_colors(\n",
    "                data,\n",
    "                title=f'Predicted colors · {\" · \".join(tags)}',\n",
    "                colors='recon',\n",
    "                colors_compare='color',\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def visualize_reconstruction_loss(data: ColorCube, *, tags: Sequence[str] = ()):\n",
    "    max_loss = np.max(data['MSE'])\n",
    "    median_loss = np.median(data['MSE'])\n",
    "    with displayer_mpl(\n",
    "        f'large-assets/ex-{nbid}-loss-colors-{tags_for_file(tags)}.png',\n",
    "        alt_text=f\"\"\"Line chart showing loss per color, titled \"{{title}}\". Y-axis: mean square error, ranging from zero to {max_loss:.2g}. X-axis: hue.\"\"\",\n",
    "    ) as show:\n",
    "        show(\n",
    "            lambda: plot_cube_series(\n",
    "                data.permute('hsv')[:, -1:, :: (data.shape[2] // -5)],\n",
    "                data.permute('svh')[:, -1:, :: -(data.shape[0] // -3)],\n",
    "                data.permute('vsh')[:, -1:, :: -(data.shape[0] // -3)],\n",
    "                title=f'Reconstruction error · {\" · \".join(tags)}',\n",
    "                var='MSE',\n",
    "                figsize=(12, 3),\n",
    "            )\n",
    "        )\n",
    "    print(f'Max loss: {max_loss:.2g}')\n",
    "    print(f'Median MSE: {median_loss:.2g}')\n",
    "\n",
    "\n",
    "def visualize_latent_space(data: ColorCube, *, tags: Sequence[str] = (), dims: Sequence[tuple[int, int, int]]):\n",
    "    with displayer_mpl(\n",
    "        f'large-assets/ex-{nbid}-latents-{tags_for_file(tags)}.png',\n",
    "        alt_text=\"\"\"Two rows of three spherical plots, titled \"{title}\". Each plot shows a vibrant collection of colored circles or balls scattered over the surface of a hypersphere, with each plot showing one 2D projection.\"\"\",\n",
    "    ) as show:\n",
    "        show(\n",
    "            lambda theme: plot_latent_grid_3d_from_cube(\n",
    "                data,\n",
    "                colors='recon',\n",
    "                colors_compare='color',\n",
    "                latents='latents',\n",
    "                title=f'Latents ·  · {\" · \".join(tags)}',\n",
    "                dims=dims,\n",
    "                dot_radius=10,\n",
    "                theme=theme,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef3d8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from utils.nb import displayer_mpl\n",
    "\n",
    "from ex_color.vis import build_stacked_figure, draw_latent_panel_from_cube, draw_color_slice, draw_cube_series_on_ax\n",
    "from ex_color.vis.plot_latent_slices import LatentD\n",
    "\n",
    "\n",
    "def draw_stacked_results(\n",
    "    latent_cube: ColorCube,\n",
    "    color_slice_cube: ColorCube,\n",
    "    loss_cube: ColorCube,\n",
    "    *,\n",
    "    latent_dims: tuple[LatentD, LatentD],\n",
    "    theme: Theme,\n",
    "    max_error: float | None = None,\n",
    "):\n",
    "    stack = build_stacked_figure(figsize=(5, 5.3), height_ratios=(2.5, 1.8, 1.2))\n",
    "    # Top: latent space. Pick any two latent axis triplets you'd like to show\n",
    "    for ax, dims in zip((stack.ax_lat1, stack.ax_lat2), latent_dims, strict=True):\n",
    "        draw_latent_panel_from_cube(\n",
    "            ax,\n",
    "            latent_cube,\n",
    "            dims=dims,\n",
    "            colors='recon',\n",
    "            colors_compare='color',\n",
    "            latents='latents',\n",
    "            dot_radius=5,\n",
    "            theme=theme,\n",
    "        )\n",
    "        ax.set_box_aspect([1, 1, 1])\n",
    "        ax.set_xlim([-0.65, 0.65])\n",
    "        ax.set_ylim([-0.65, 0.65])\n",
    "\n",
    "    # Middle: reconstructed colors; pick a single slice index\n",
    "    draw_color_slice(\n",
    "        stack.ax_colors,\n",
    "        color_slice_cube.permute('svh')[:, 1:, :],\n",
    "        -1,  # Full saturation\n",
    "        pretty=True,\n",
    "        colors='recon',\n",
    "        colors_compare='color',\n",
    "    )\n",
    "    stack.ax_colors.set_title('')\n",
    "    stack.ax_colors.set_xlabel('')\n",
    "    stack.ax_colors.xaxis.set_visible(False)\n",
    "\n",
    "    # Bottom: loss vs. color series for a single cube variant\n",
    "    draw_cube_series_on_ax(\n",
    "        stack.ax_loss,\n",
    "        loss_cube.permute('hsv')[:, -1:, :: (loss_cube.shape[2] // -5)],\n",
    "        var='MSE',\n",
    "    )\n",
    "    stack.ax_loss.set_title('')\n",
    "    stack.ax_loss.set_ylabel('MSE')\n",
    "    stack.ax_loss.set_ylim(0, max_error)\n",
    "    # format as :.2g\n",
    "    # stack.ax_loss.yaxis.set_major_formatter('{x:.1g}')\n",
    "    return stack.fig\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class StackResults:\n",
    "    tags: Sequence[str]\n",
    "    latent_cube: ColorCube\n",
    "    color_slice_cube: ColorCube\n",
    "    loss_cube: ColorCube\n",
    "\n",
    "\n",
    "def visualize_stacked_results(\n",
    "    res: StackResults,\n",
    "    *,\n",
    "    latent_dims: tuple[LatentD, LatentD],\n",
    "    max_error: float | None = None,\n",
    "):\n",
    "    with displayer_mpl(\n",
    "        f'large-assets/ex-{nbid}-results-{tags_for_file(res.tags)}.png',\n",
    "        alt_text=\"\"\"Composite figure with two latent panels (top), a color slice (middle), and a loss chart (bottom).\"\"\",\n",
    "    ) as show:\n",
    "        show(\n",
    "            lambda theme: draw_stacked_results(\n",
    "                res.latent_cube,\n",
    "                res.color_slice_cube,\n",
    "                res.loss_cube,\n",
    "                latent_dims=latent_dims,\n",
    "                theme=theme,\n",
    "                max_error=max_error,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8fcb76",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "The first model we'll test is one that is trained without the subspace term, but with the unitarity regularization term included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b26721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 10.1 no.2.10.1:Training with: ['reg-separate', 'reg-anchor', 'reg-anti-subspace']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 10.1 li.fa.ut.se:Seed set to 0\n",
      "I 10.1 ex.se:  PyTorch set to deterministic mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 10.2 li.py.ut.ra:GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 10.2 li.py.ut.ra:TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 10.2 li.py.ut.ra:HPU available: False, using: 0 HPUs\n",
      "max_steps: 1501, train_loader length: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mz0r\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/wandb/run-20250923_131942-uwdojomi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/z0r/ex-preppy/runs/uwdojomi' target=\"_blank\">Ex 2.10.1: Ablate red (only), 5D, fewer labels</a></strong> to <a href='https://wandb.ai/z0r/ex-preppy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/z0r/ex-preppy' target=\"_blank\">https://wandb.ai/z0r/ex-preppy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/z0r/ex-preppy/runs/uwdojomi' target=\"_blank\">https://wandb.ai/z0r/ex-preppy/runs/uwdojomi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width: 100%; padding: 5px 0; font-family: monospace\">\n",
       "  <div style=\"position: relative; height: calc(1em * 5/3); width: 100%; margin-bottom: 2em\">\n",
       "    <div style=\"position: absolute; top: 100%; height: 3.5px; left: 0; width: 100%; background: linear-gradient(to right, var(--h1) 0.0%, var(--h1) 2.0%, var(--h1) 4.1%, var(--h1) 6.1%, var(--h1) 8.2%, var(--h1) 10.2%, var(--h1) 12.2%, var(--h1) 14.3%, var(--h0) 16.3%, var(--h1) 18.4%, var(--h1) 20.4%, var(--h1) 22.4%, var(--h1) 24.5%, var(--h1) 26.5%, var(--h1) 28.6%, var(--h1) 30.6%, var(--h0) 32.7%, var(--h1) 34.7%, var(--h1) 36.7%, var(--h1) 38.8%, var(--h1) 40.8%, var(--h1) 42.9%, var(--h1) 44.9%, var(--h1) 46.9%, var(--h0) 49.0%, var(--h1) 51.0%, var(--h1) 53.1%, var(--h1) 55.1%, var(--h1) 57.1%, var(--h1) 59.2%, var(--h1) 61.2%, var(--h1) 63.3%, var(--h0) 65.3%, var(--h1) 67.3%, var(--h1) 69.4%, var(--h1) 71.4%, var(--h1) 73.5%, var(--h1) 75.5%, var(--h1) 77.6%, var(--h1) 79.6%, var(--h0) 81.6%, var(--h1) 83.7%, var(--h1) 85.7%, var(--h1) 87.8%, var(--h1) 89.8%, var(--h1) 91.8%, var(--h1) 93.9%, var(--h1) 95.9%, var(--h0) 98.0%, var(--h2) 100.0%);--h0:color(from currentColor srgb r g b / 0.06);--h1:color(from currentColor srgb r g b / 0.25);--h2:color(from currentColor srgb r g b / 0.56)\"></div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: -0.1%; border-left: 0.5px solid currentColor\">0.0119</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 9.5%; border-left: 0.5px solid currentColor\">0.0119</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 19.1%; border-left: 0.5px solid currentColor\">0.0037</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 28.7%; border-left: 0.5px solid currentColor\">0.0014</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 38.3%; border-left: 0.5px solid currentColor\">0.0022</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 47.9%; border-left: 0.5px solid currentColor\">0.0015</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 57.5%; border-left: 0.5px solid currentColor\">0.0235</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 67.1%; border-left: 0.5px solid currentColor\">0.0027</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 76.7%; border-left: 0.5px solid currentColor\">0.0007</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; left: 86.3%; border-left: 0.5px solid currentColor\">0.0004</div>\n",
       "    <div style=\"position: absolute; top: 100%; font-size: 70%; padding: 3px 2px 0; right: 0.1%; border-right: 0.5px solid currentColor\">0.0001</div>\n",
       "    <div style=\"position: absolute; bottom: -4px; left: calc(100.0% - 4px)\">\n",
       "      <div style=\"border-left: 4px solid transparent; border-right: 4px solid transparent; border-bottom: 4px solid currentColor\"></div>\n",
       "    </div>\n",
       "    <div style=\"position: absolute; height: 100%; width: 100.0%; background-color: color(from currentColor srgb r g b / 0.1); border-bottom: 1px solid currentColor\"></div>\n",
       "    <div style=\"position: absolute; width: 100%; height: 100%; text-align: center; line-height: calc((1em * 5/3) / 0.9); font-size: 90%; white-space: nowrap; overflow: hidden; text-overflow: ellipsis; border-bottom: 1px dashed color(from currentColor srgb r g b / 0.5)\"><b>Training</b>: 100.0% [1501/1501] [<b>00:12</b>/<00:00, 123.62 it/s]</div>\n",
       "  </div>\n",
       "  <div style=\"display: grid; grid-template-columns: repeat(3, minmax(80px, 1fr)); gap: 5px 0px; width: 100%; margin: 1em 0; font-size: 0.85em\">\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">v_num</div>\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">val_loss</div>\n",
       "    <div style=\"font-weight: bold; border-bottom: 0.5px solid currentColor; padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">train_loss</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">jomi</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">0.0001315</div>\n",
       "    <div style=\"padding: 2px 10px; text-align: left; overflow: hidden; text-overflow: ellipsis; white-space: nowrap\">3.313e-05</div>\n",
       "  </div>\n",
       "</div>"
      ],
      "text/plain": [
       "Training: 100.0% [1501/1501]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting phase: Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_steps=1501` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I 24.2 li.py.ut.ra:`Trainer.fit` stopped: `max_steps=1501` reached.\n",
      "I 24.2 ex.ca.la:Label frequencies (n=89000): _any: 0.067%, red: 0.067%\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>labels/_any</td><td>▁</td></tr><tr><td>labels/epoch/_any</td><td>▁█▆▆██▇█▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>labels/epoch/red</td><td>▁▇▅█▆▇▆▆▆▆▆▆▆▆▆▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>labels/red</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_recon</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▄▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_reg-anchor</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_reg-anti-subspace</td><td>▂▁▁▁▁▁▁▁▁▁▄▁▁▁▂▁▁▁▂▁█▁▁▃▂▄▁▂▃▃▃▂▁▂▁▂▁▂▃▃</td></tr><tr><td>train_reg-separate</td><td>▇▄▄▆█▄▅▃▃▂▁▂▂▂▂▁▂▃▂▃▂▂▁▂▂▁▂▁▁▂▂▂▂▁▃▂▂▁▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>val_loss</td><td>▂▁▂▁█▂▁▁▁</td></tr><tr><td>val_recon</td><td>▂▁▂▁█▂▁▁▁</td></tr><tr><td>val_reg-anchor</td><td>█▇█▄▄▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>92</td></tr><tr><td>labels/_any</td><td>0.00067</td></tr><tr><td>labels/epoch/_any</td><td>0.00067</td></tr><tr><td>labels/epoch/red</td><td>0.00067</td></tr><tr><td>labels/red</td><td>0.00067</td></tr><tr><td>train_loss</td><td>4e-05</td></tr><tr><td>train_recon</td><td>4e-05</td></tr><tr><td>train_reg-anchor</td><td>0</td></tr><tr><td>train_reg-anti-subspace</td><td>0.01076</td></tr><tr><td>train_reg-separate</td><td>0.29428</td></tr><tr><td>trainer/global_step</td><td>1487</td></tr><tr><td>val_loss</td><td>0.00013</td></tr><tr><td>val_recon</td><td>0.00013</td></tr><tr><td>val_reg-anchor</td><td>0.00021</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Ex 2.10.1: Ablate red (only), 5D, fewer labels</strong> at: <a href='https://wandb.ai/z0r/ex-preppy/runs/uwdojomi' target=\"_blank\">https://wandb.ai/z0r/ex-preppy/runs/uwdojomi</a><br> View project at: <a href='https://wandb.ai/z0r/ex-preppy' target=\"_blank\">https://wandb.ai/z0r/ex-preppy</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/tmp/wandb/run-20250923_131942-uwdojomi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reload dopesheet: makes tweaking params during development easier\n",
    "dopesheet = Dopesheet.from_csv(f'./ex-{nbid}-dopesheet.csv')\n",
    "\n",
    "model = await train(\n",
    "    dopesheet,\n",
    "    [reg_separate, reg_anchor, reg_anti_subspace],\n",
    "    K,\n",
    "    N,\n",
    "    seed=0,  # Arbitrary but not cherry-picked\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "482e58c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.10.1-pred-colors-no-intervention-no-subspace.dark.png?v=vNv89VXKgkvNk1HF4KOwP14nTBtl-ttmsJsN9XjhG-0\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.10.1-pred-colors-no-intervention-no-subspace.png?v=vNv89VXKgkvNk1HF4KOwP14nTBtl-ttmsJsN9XjhG-0\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.10.1-pred-colors-no-intervention-no-subspace.png?v=vNv89VXKgkvNk1HF4KOwP14nTBtl-ttmsJsN9XjhG-0\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors · no intervention · no subspace · V vs H by S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors · no intervention · no subspace · V vs H by S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "no_intervention_results = StackResults(\n",
    "    tags=['no intervention', 'no subspace'],\n",
    "    latent_cube=await test(model, rgb_cube),\n",
    "    color_slice_cube=await test(model, hsv_cube),\n",
    "    loss_cube=await test(model, hd_hsv_cube),\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "visualize_reconstructed_cube(no_intervention_results.color_slice_cube.permute('svh'), tags=no_intervention_results.tags)\n",
    "# visualize_reconstruction_loss(no_intervention_results.loss_cube, tags=no_intervention_results.tags)\n",
    "# visualize_latent_space(\n",
    "#     no_intervention_results.latent_cube,\n",
    "#     tags=no_intervention_results.tags,\n",
    "#     dims=[(1, 0, 2), (2, 0, 1), (3, 0, 1), (4, 1, 2), (3, 2, 4), (4, 3, 0)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456fd4b",
   "metadata": {},
   "source": [
    "Reconstruction loss looks about as good as last time. There's higher loss around red even without intervenion, but it's still low.\n",
    "\n",
    "Latent space looks suprisingly good: the area opposing red is clear, and there's a pronounced collection of reds near the anchor point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4f1dc",
   "metadata": {},
   "source": [
    "### Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a02428ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.10.1-pred-colors-ablated-no-subspace.dark.png?v=tLesmef0EKODHEe9r3JCX35d1iWmdiQ1KWVp_q8_xCs\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.10.1-pred-colors-ablated-no-subspace.png?v=tLesmef0EKODHEe9r3JCX35d1iWmdiQ1KWVp_q8_xCs\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.10.1-pred-colors-ablated-no-subspace.png?v=tLesmef0EKODHEe9r3JCX35d1iWmdiQ1KWVp_q8_xCs\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors · ablated · no subspace · V vs H by S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors · ablated · no subspace · V vs H by S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.surgery import ablate\n",
    "\n",
    "ablated_model = ablate(model, 'bottleneck', [0])\n",
    "\n",
    "ablation_results = StackResults(\n",
    "    tags=['ablated', 'no subspace'],\n",
    "    latent_cube=await test(ablated_model, rgb_cube),\n",
    "    color_slice_cube=await test(ablated_model, hsv_cube),\n",
    "    loss_cube=await test(ablated_model, hd_hsv_cube),\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "visualize_reconstructed_cube(ablation_results.color_slice_cube.permute('svh'), tags=ablation_results.tags)\n",
    "# visualize_reconstruction_loss(ablation_results.loss_cube, tags=ablation_results.tags)\n",
    "# visualize_latent_space(\n",
    "#     ablation_results.latent_cube,\n",
    "#     tags=ablation_results.tags,\n",
    "#     dims=[(1, 0, 2), (2, 0, 1), (3, 0, 1), (4, 1, 2), (3, 2, 4), (4, 3, 0)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6061e48",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "187c5a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.10.1-pred-colors-pruned-no-subspace.dark.png?v=p0HVCoqJD_q5oj8gNxqm9_9HwrsXxG3c2kQ2T4YsLvI\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.10.1-pred-colors-pruned-no-subspace.png?v=p0HVCoqJD_q5oj8gNxqm9_9HwrsXxG3c2kQ2T4YsLvI\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.10.1-pred-colors-pruned-no-subspace.png?v=p0HVCoqJD_q5oj8gNxqm9_9HwrsXxG3c2kQ2T4YsLvI\" alt=\"Plot showing four slices of the HSV cube, titled &quot;Predicted colors · pruned · no subspace · V vs H by S&quot;. Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color.\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Plot showing four slices of the HSV cube, titled \"Predicted colors · pruned · no subspace · V vs H by S\". Nominally, each slice has constant saturation, but varies in value (brightness) from top to bottom, and in hue from left to right. Each color value is represented as a square patch of that color. The outer portion of the patches shows the color as reconstructed by the model; the inner portion shows the true (input) color."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "from ex_color.surgery import prune\n",
    "\n",
    "pruned_model = prune(model, 'bottleneck', [0])\n",
    "\n",
    "pruned_results = StackResults(\n",
    "    tags=['pruned', 'no subspace'],\n",
    "    latent_cube=await test(pruned_model, rgb_cube),\n",
    "    color_slice_cube=await test(pruned_model, hsv_cube),\n",
    "    loss_cube=await test(pruned_model, hd_hsv_cube),\n",
    ")\n",
    "clear_output()\n",
    "\n",
    "visualize_reconstructed_cube(pruned_results.color_slice_cube.permute('svh'), tags=pruned_results.tags)\n",
    "# visualize_reconstruction_loss(pruned_results.loss_cube, tags=pruned_results.tags)\n",
    "# visualize_latent_space(\n",
    "#     pruned_results.latent_cube,\n",
    "#     tags=pruned_results.tags,\n",
    "#     dims=[(1, 0, 2), (2, 0, 1), (3, 0, 1), (4, 1, 2), (3, 2, 4), (4, 3, 0)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e87ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd20e021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.10.1-results-no-intervention-no-subspace.dark.png?v=vg8vjtOLDWOtzp-q4Mm7Ju-sio76YMdnEp1C45qKgR4\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.10.1-results-no-intervention-no-subspace.png?v=vg8vjtOLDWOtzp-q4Mm7Ju-sio76YMdnEp1C45qKgR4\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.10.1-results-no-intervention-no-subspace.png?v=vg8vjtOLDWOtzp-q4Mm7Ju-sio76YMdnEp1C45qKgR4\" alt=\"Composite figure with two latent panels (top), a color slice (middle), and a loss chart (bottom).\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Composite figure with two latent panels (top), a color slice (middle), and a loss chart (bottom)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.10.1-results-ablated-no-subspace.dark.png?v=4b55xVbMj54jPPcKXti6p6EgXvmbNHghqE52E4PK3Gs\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.10.1-results-ablated-no-subspace.png?v=4b55xVbMj54jPPcKXti6p6EgXvmbNHghqE52E4PK3Gs\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.10.1-results-ablated-no-subspace.png?v=4b55xVbMj54jPPcKXti6p6EgXvmbNHghqE52E4PK3Gs\" alt=\"Composite figure with two latent panels (top), a color slice (middle), and a loss chart (bottom).\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Composite figure with two latent panels (top), a color slice (middle), and a loss chart (bottom)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<picture>\n",
       "  <source srcset=\"large-assets/ex-2.10.1-results-pruned-no-subspace.dark.png?v=weuSxsNPicDI7urGzg2F3zYRDGE968xEWLVCVXJ3LyU\" media=\"(prefers-color-scheme: dark)\" />\n",
       "  <source srcset=\"large-assets/ex-2.10.1-results-pruned-no-subspace.png?v=weuSxsNPicDI7urGzg2F3zYRDGE968xEWLVCVXJ3LyU\" media=\"(prefers-color-scheme: light)\" />\n",
       "  <img src=\"large-assets/ex-2.10.1-results-pruned-no-subspace.png?v=weuSxsNPicDI7urGzg2F3zYRDGE968xEWLVCVXJ3LyU\" alt=\"Composite figure with two latent panels (top), a color slice (middle), and a loss chart (bottom).\" />\n",
       "</picture>"
      ],
      "text/plain": [
       "Composite figure with two latent panels (top), a color slice (middle), and a loss chart (bottom)."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_error = np.max(\n",
    "    [\n",
    "        no_intervention_results.loss_cube['MSE'],\n",
    "        ablation_results.loss_cube['MSE'],\n",
    "        pruned_results.loss_cube['MSE'],\n",
    "    ]\n",
    ")\n",
    "visualize_stacked_results(\n",
    "    no_intervention_results,\n",
    "    latent_dims=((3, 0, 1), (3, 2, 4)),\n",
    "    max_error=max_error,\n",
    ")\n",
    "visualize_stacked_results(\n",
    "    ablation_results,\n",
    "    latent_dims=((3, 0, 1), (3, 2, 4)),\n",
    "    max_error=max_error,\n",
    ")\n",
    "visualize_stacked_results(\n",
    "    pruned_results,\n",
    "    latent_dims=((2, None, 0), (2, 1, 3)),\n",
    "    max_error=max_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b26fcb",
   "metadata": {},
   "source": [
    "This is almost as good as last time: about 1/3 the loss for red (higher would be better), with fairly smooth falloff to the yellow and purple. There's hardly any error for other colors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17177769",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We can delete _red_ without deleting _cyan_ or other colors, even without labelling anything other than _red_. The error at _red_ could be higher; perhaps that could be achieved with more hyperparameter tuning.\n",
    "\n",
    "When we first tried this (see git history), it didn't work well: _red_ was isolated, but the falloff toward other colors was very sharp, so there was hardly any impact on other warm colors. We fixed that by adjusting the hyperparameter schedule: instead of having Anchor and Anti-subspace in conflict the whole time, the schedule starts with a high Anti-subspace weight, and transitions to high Anchor weight around half-way through. This causes the network to section off the anchor (first) dimension at the start of training, and pulls _red_ into that space once the manifold has already been established."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-color-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
